---
title: "Projeto Métodos de Aprendizagem Não supervisionados - PCA na base de dados com Imputação"
author: "grupo 6sigma"
date: "2023-05-10"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
---

### Bibliotecas

```{r}
pacman::p_load(
               "sjstats", "plotrix", "skimr", "viridis",
               "txtplot", "cluster", "tidyverse", "RColorBrewer",
               "caret", "factoextra", "mclust", "htmlTable",
               "readr", "naniar", "here", "modeest",
               "psych", "corrplot", "haven", "kableExtra",
               "haven", "dplyr" , "magrittr", "mice"
               )
options(repr.plot.width=6, repr.plot.height=6)
```

## Leitura dos dados

```{r}
IrlandaImput <- read_rds("IrlandaImput.rds")
```


# Tratamento dos dados
  Após realizada a limpeza dos dados, podemos então passar finalmente para a criação de PCA, a fim de se conseguir reduzir a dimensionalidade da base de dados, que possui 86 colunas.
  Antes de prosseguir, é necessário reter alguns pontos sobre como aplicar o PCA:

  1. O PCA é mais eficaz quando as variáveis estão correlacionadas entre si.

  2. Antes de aplicar o PCA, é importante verificar se as variáveis estão em escalas comparáveis. Variáveis em diferentes escalas podem ter diferentes variações e isso pode distorcer a análise do PCA.

## Selecionar Colunas

Devido ao elevado número de colunas, iremos primeiramente eliminar algumas colunas, a fim de facilitar o processo de aplicar o teste KMO, pois,torna-se computacionalmente intensiva

```{r}
colnames(IrlandaImput)
```


```{r}
# Por algum motivo, a variável GRADE faz com que o teste KMO dê erro
# Aqui serão apagadas todas as variáveis que, ou podem ser substituidas, ou não tem valor nenhum

Apagar <- c("HISCED", "MISCED", "GRADE", "REPEAT", "ATTLNACT", "FISCED", "DISCLIMA", "IMMIG", "ICTSCH", "JOYREADP", "HISEI")
IrlandaImput <- IrlandaImput[, -which(names(IrlandaImput) %in% Apagar)]
```


## Correlações das colunas
```{r, results='hide'}
CorrIrlandaImput <- cor(IrlandaImput)
```

## KMO measure
```{r}
kmo_result <- KMO(IrlandaImput)
kmo_result
```
O KMO (Kaiser-Meyer-Olkin) é uma medida estatística utilizada para avaliar a adequação dos dados para realizar uma análise de fator ou análise de componentes principais (PCA).
O valor do KMO varia de 0 a 1 e, quanto mais próximo de 1, melhor a adequação dos dados para uma análise de fator ou PCA. Valores de KMO acima de 0,6 são geralmente considerados adequados para análises exploratórias, enquanto valores acima de 0,8 são considerados muito bons.

### Seleceção das melhores variáveis
Vamos então visualizar as variáveis que não são adequadas para aplica o PCA

```{r}
# Obtém as variáveis com KMO abaixo de 0.5
MelhorKMO <- names(kmo_result$MSAi)[kmo_result$MSAi > 0.6]
IrlandaImput <- IrlandaImput[, which(names(IrlandaImput) %in% MelhorKMO)]
```

```{r}
correlation <- cor(IrlandaImput)

corrplot(correlation,
         type = "upper",
         tl.cex = 0.6,
         addshade = "positive") # show only upper part
```


## Teste de esfericidade de Bartlett em uma matriz de correlação.

O teste de esfericidade de Bartlett é um teste estatístico que avalia se as variáveis em um conjunto de dados estão correlacionadas entre si. Ele verifica a hipótese nula de que a matriz de correlação populacional é uma matriz de identidade, o que significa que as variáveis são independentes e não correlacionadas.

```{r}
cortest.bartlett(IrlandaImput)
```
Se o valor-p (p-value) calculado no teste de esfericidade de Bartlett for menor que 0.05, isso sugere evidências estatísticas para rejeitar a hipótese nula de que as variáveis são independentes e não correlacionadas, por outras palavras, existe uma correlação significativa entre as variáveis em questão. Isso significa que as variáveis não podem ser consideradas independentes, existindo algum grau de relação entre elas.

# Estandardizar os dados

```{r}
data_scaled <- scale(IrlandaImput)
data_scaled %>% glimpse()
```

# PCA

Nesta parte, passaremos então para o processo de criação de PCA's. Podemos então começar por pensar algumas ideias por alto, podendo ser estas:

* **PCA de Desempenho Acadêmico**:
    - Variáveis de interesse: Pontuações em diferentes domínios acadêmicos, como leitura, matemática e ciências.
    - Objetivo: Compreender a estrutura subjacente do desempenho acadêmico dos alunos e identificar padrões gerais de habilidades e competências.

* **PCA de Fatores Socioeconômicos**:
    - Variáveis de interesse: Variáveis socioeconômicas, como o nível de educação dos pais, ocupação dos pais, renda familiar, acesso a recursos educacionais, etc.
    - Objetivo: Explorar as relações entre os fatores socioeconômicos e o desempenho acadêmico dos alunos, bem como identificar grupos de alunos com perfis socioeconômicos semelhantes.

* **PCA de Atitudes e Comportamentos**:
    - Variáveis de interesse: Variáveis relacionadas a atitudes, motivação, autoeficácia, disciplina, participação em atividades extracurriculares, etc.
    - Objetivo: Identificar padrões de atitudes e comportamentos dos alunos que podem influenciar seu desempenho académico e bem-estar geral.

* **PCA de Ambiente Escolar**:
    - Variáveis de interesse: Variáveis relacionadas ao ambiente escolar, como tamanho da turma, recursos educacionais disponíveis, clima escolar, relacionamento professor-aluno, etc.
    - Objetivo: Explorar a relação entre o ambiente escolar e o desempenho dos alunos, bem como identificar características importantes do ambiente que afetam o aprendizado.

## Criação do PCA

```{r}
dim(data_scaled)
```

```{r}
pc1 <- principal(data_scaled, nfactors=10, rotate="none")
```

### Kaiser Criterion

```{r}
valores <- round(pc1$values,3)
valores
```
Visualizando os valores acima, podemos então concluir que ```{r} length(valores[valores > 1]) ```

```{r}
length(valores[valores > 1])
```


```{r}
plot(pc1$values, type = "b", main = "Scree plot for Irland dataset", 
     xlab = "Number of PC", ylab = "Eigenvalue")
```

De seguida, iremos analisar ambos os valores, mas é necessário ter em conta o seguinte, para uma melhor interpretação dos resultados:

> SS loadings: Representa a soma dos quadrados das cargas dos componentes principais. Quanto maior o valor, mais bem os componentes capturam a variabilidade dos dados.

> Proportion Var: Indica a proporção da variância total explicada por cada componente principal. Quanto maior o valor, mais bem o componente explica a variabilidade dos dados em relação ao total.

> Cumulative Var: Representa a variância cumulativa explicada pelos componentes principais até o componente atual. É a soma acumulada das proporções de variância. Quanto maior o valor, mais bem os componentes principais explicam a variabilidade total dos dados à medida que adicionam-se mais componentes.

## Experiência com ```{r} length(valores[valores > 1]) ```

```{r}
pc12 <- principal(data_scaled, nfactors = 12, rotate = "none")
pc12$loadings
round(pc12$communality,2)
```

```{r}
pc12r <- principal(data_scaled, nfactors= 12, rotate="varimax")
pc12r$loadings
round(pc12r$communality,2)
```

```{r}
# RC1 - Psicólogo do estudante
# RC4 - Dedicação do estudante
# RC2 - Notas/ Dificuldades dos estudantes
# RC3 - Preocupação com o mercado de trabalho
# RC7 - Suporte que o estudante recebe
```


## Experiência com 7

```{r}
pc7 <- principal(data_scaled, nfactors = 7, rotate = "none")
pc7$loadings
round(pc7$communality,2)
```

```{r}
pc7r <- principal(data_scaled, nfactors= 7, rotate="varimax")
pc7r$loadings
round(pc7r$communality,2)
```

```{r}
# RC1 - Vida Social do Aluno
# RC2 - Competências académicas do estudante
# RC3 - Informação que o estudante possui
# RC4 - Motivação do estudante
# RC5 - Condições socioeconomicas do estudante
```

```{r}
pc7sc <- principal(data_scaled, nfactors = 13, rotate = "varimax", scores = TRUE)
round(pc7sc$scores,3)

mean(pc7sc$scores[,1])
sd(pc7sc$scores[,1])
```

```{r}
IrlandaImput$SociaLife <- pc7sc$scores[,2]
IrlandaImput$Knowledge <- pc7sc$scores[,3]
IrlandaImput$Information <- pc7sc$scores[,4]
IrlandaImput$Motivation <- pc7sc$scores[,1]
IrlandaImput$socioeconomic <- pc7sc$scores[,6]
```

```{r}
dim(IrlandaImput)
```

```{r}
IrlandaImput[,44:48]
```

```{r}
corr <- cor(IrlandaImput[,44:48])
par(oma = c(2, 2, 2, 2))   # space rounf the graph
corrplot.mixed(corr,
        order = "hclust",
        tl.pos = "lt",
        upper = "ellipse")
```


```{r}
pc_dist <- dist(IrlandaImput[,44:48])
hclust  <- hclust(pc_dist, method='ward.D2')
plot(hclust, hang=-1, labels=FALSE)

groups.k5 <- cutree(hclust, k = 3)
rect.hclust(hclust, k = 3, border="red")
```

```{r}
plot(silhouette(groups.k5, pc_dist))
```

```{r}
pc_dist <- dist(IrlandaImput[,44:48])
hclust  <- hclust(pc_dist, method='complete')
plot(hclust, hang=-1, labels=FALSE)

groups.k5_c <- cutree(hclust, k=3)
rect.hclust(hclust, k=3, border="red")
```

```{r}
plot(silhouette(groups.k5_c, pc_dist))
```

```{r}
table(groups.k5,groups.k5_c)
```

```{r}
# K-Means: number of clusters
wssplot <- function(xx, nc=15, seed=1234){
  wss <- (nrow(xx)-1)*sum(apply(xx,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(xx, centers=i)$withinss)}
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")}
wssplot(IrlandaImput[,44:48], nc=10)
```

```{r}
#K-means cluster com K=6
kmeans.k6 <- kmeans(IrlandaImput[,44:48], 4, nstart=100)
IrlandaImput = IrlandaImput %>% mutate(cluster = kmeans.k6$cluster)
```

```{r}
table(groups.k5, IrlandaImput$cluster)
```

```{r}
#Barplot of average score in each principal component within each cluster
barplot(colMeans(subset(IrlandaImput,cluster==1)[,44:48]),main= "Cluster 1 - Average score in each principal component")
barplot(colMeans(subset(IrlandaImput,cluster==2)[,44:48]),main= "Cluster 2 - Average score in each principal component")
barplot(colMeans(subset(IrlandaImput,cluster==3)[,44:48]),main= "Cluster 3 - Average score in each principal component")
barplot(colMeans(subset(IrlandaImput,cluster==4)[,44:48]),main= "Cluster 4 - Average score in each principal component")
# barplot(colMeans(subset(IrlandaImput,cluster==5)[,44:48]),main= "Cluster 4 - Average score in each principal component")
```

```{r}
std_data <- scale(IrlandaImput[,44:48])
pam.k4 <- pam(std_data, 4)
```

```{r}
table(groups.k5,pam.k4$clustering)
```

```{r}
clusplot(pam.k4, labels = 4, col.p = pam.k4$clustering)
```

```{r}
data <- IrlandaImput[,44:48]

BIC <- mclustBIC(data)
plot(BIC)
```

```{r}
### GMM
set.seed(1233)

# Apply GMM with 5 components
results.G6 <- Mclust(data, G = 5)
summary(results.G6, parameters = TRUE)
```

```{r}
# Some results
results.G6$modelName          # Optimal selected model
results.G6$G                  # Optimal number of cluster
head(results.G6$z, 5)         # Probability to belong to a given cluster
head(results.G6$classification, 5) # Cluster assignment of each observation
```

```{r}
# select VEV, different volume, equal shape, different directions
plot(results.G6, what = "classification")
```
```{r}
plot(results.G6, what = "uncertainty")
```




