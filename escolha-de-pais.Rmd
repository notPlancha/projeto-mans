---
title: "Projeto"
author: "grupo 6sigma"
date: "2023-05-10"
output: html_notebook
---

### Bibliotecas
```{r}
library(skimr)
library(txtplot)
library(cluster)
library(tidyverse)
library(caret)
library(factoextra)
library(mclust)
library(readr)
library(naniar)
library(here)
library(psych)
library(corrplot)
library(haven)
library(dplyr)
library(magrittr)
options(repr.plot.width=6, repr.plot.height=6)
```

# Leitura dos dados
```{r}
dados <- readRDS(here("data", "STU_QQQ_5.rds"))
dados
```


## Omissos de cada coluna
```{r}
colSums(is.na(dados))
```

```{r}
# A coluna dos Paises não tem nulos
sum(is.na(dados$CNT))
```

## Países Existentes na base de dados
```{r}
unique(dados$CNT)
```

### Visualização das características de cada um dos países
```{r}
dados %>%
  mutate(NumNulos = rowSums(is.na(.))) %>%
  group_by(CNT) %>%
  summarize(TotalNulos = sum(NumNulos),
            NumLinhas = n(),
            PercentNulos = (TotalNulos / (NumLinhas * ncol(dados))) * 100,
            MeanScience = mean(PV1SCIE, na.rm = TRUE),
            MeanRead = mean(PV1READ, na.rm = TRUE),
            MeanMath = mean(PV1MATH, na.rm = TRUE),
            .groups = "drop") %>% 
  arrange(desc(NumLinhas))
```

# Irlanda
```{r}
Irlanda <- dados %>% filter(CNT == "IRL")
Irlanda
```

## Características da Irlanda
```{r, results='hide'}
dim(Irlanda)
describe(Irlanda)
```

```{r}
# str(Irlanda)
```

```{r}
# summary(Irlanda)
```

```{r}
skimr::skim(Irlanda)
```

```{r}
summary(Irlanda)
```


## Limpeza dos valores omissos

```{r}
IrlandaSemiLimpa <- Irlanda %>% select(where(~ !all(is.na(.))))
dim(IrlandaSemiLimpa)
```
```{r}
nulos_percent <- IrlandaSemiLimpa %>%
  summarise_all(~ mean(is.na(.)) * 100)

colunas_com_nulos <- colnames(nulos_percent)[nulos_percent > 30]
colunas_com_nulos
```
```{r}
Irlanda <- select(Irlanda, -one_of(colunas_com_nulos))
```


```{r}
options(scipen = 999)
Irlanda %>%
  summarise(across(where(is.labelled), \(x) attributes(x)$label)) %>% 
  tidylog::pivot_longer(everything(), names_to = "Column", values_to = "Description") %>% 
  rowwise() %>% 
  mutate(Type = sapply(Column, \(x) class(dados[[x]])[3])) %>% 
  mutate(First_5_Values = sapply(Column, \(x) paste(head(na.omit(dados[[x]]), 5) , collapse = ", "))) %>%
  mutate(naPercent = sapply(Column, \(x) Irlanda %>% zap_labels() %>% .[[x]] %>% is.na() %>% mean %>% "*"(100) %>% round(2))) -> dfI.desc
dfI.desc %>% View()
dfI.desc
```

```{r}
library(mice)
Irlanda <- IrlandaSemiLimpa %>% zap_labels() %>% mice(method = "norm.predict", m = 1)
Irlanda <- complete(Irlanda)

Irlanda %>% summarise_all(~ mean(is.na(.)) * 100)
```

```{r, results='hide'}
describe(Irlanda)
```
```{r}
colunas_nao_numericas <- names(Irlanda)[!sapply(Irlanda, is.numeric)]
colunas_nao_numericas
```
```{r}
valores_unicos <- lapply(Irlanda[colunas_nao_numericas], unique)

# Exibir os valores únicos de cada coluna
for (i in seq_along(valores_unicos)) {
  coluna <- colunas_nao_numericas[i]
  valores <- valores_unicos[[i]]
  cat("Valores únicos da coluna", coluna, ":\n")
  print(valores)
  cat("\n")
}
```


```{r}
colunas_nao_numericas <- colunas_nao_numericas[-5]
colunas_nao_numericas

Irlanda[colunas_nao_numericas] <- lapply(Irlanda[colunas_nao_numericas], as.factor)
Irlanda <- Irlanda %>% select_if(is.numeric)
```

# Tratamento dos dados
  Após realizada a limpeza dos dados, podemos então passar finalmente para a criação de PCA, a fim de se conseguir reduzir a dimensionalidade da base de dados, que possui 86 colunas.
  Antes de prosseguir, é necessário reter alguns pontos sobre como aplicar o PCA:

  1. O PCA é mais eficaz quando as variáveis estão correlacionadas entre si.

  2. Antes de aplicar o PCA, é importante verificar se as variáveis estão em escalas comparáveis. Variáveis em diferentes escalas podem ter diferentes variações e isso pode distorcer a análise do PCA.
  
## Correlações das colunas
```{r, results='hide'}
#Correlation plot with colors (too many attributes)

correlation <- cor(Irlanda)
corrplot(correlation)

#Correlation matrix
round(correlation, 3)
```

## KMO measure
```{r}
KMO(correlation)
```
O KMO (Kaiser-Meyer-Olkin) é uma medida estatística utilizada para avaliar a adequação dos dados para realizar uma análise de fator ou análise de componentes principais (PCA).
O valor do KMO varia de 0 a 1 e, quanto mais próximo de 1, melhor a adequação dos dados para uma análise de fator ou PCA. Valores de KMO acima de 0,6 são geralmente considerados adequados para análises exploratórias, enquanto valores acima de 0,8 são considerados muito bons.

### Possiveis variáveis fracas
Vamos então visualizar as variáveis que não são adequadas para aplica o PCA

```{r}
# kmo_result <- KMO(correlation)
# str(kmo_result)
# Obtém as variáveis com KMO abaixo de 0.6
# low_kmo_variables <- kmo_result$MSAi[kmo_result$MSAi < 0.6]
# length(low_kmo_variables)
# low_kmo_variables
```
### Possiveis variáveis fortes

```{r}
# Obtém as variáveis com KMO acima, ou igual, a 0.8
# high_kmo_variables <- kmo_result$MSAi[kmo_result$MSAi >= 0.8]
# length(high_kmo_variables)
# high_kmo_variables
```

## Teste de esfericidade de Bartlett em uma matriz de correlação.

O teste de esfericidade de Bartlett é um teste estatístico que avalia se as variáveis em um conjunto de dados estão correlacionadas entre si. Ele verifica a hipótese nula de que a matriz de correlação populacional é uma matriz de identidade, o que significa que as variáveis são independentes e não correlacionadas.

```{r}
cortest.bartlett(correlation)
```
Se o valor-p (p-value) calculado no teste de esfericidade de Bartlett for menor que 0.05, isso sugere evidências estatísticas para rejeitar a hipótese nula de que as variáveis são independentes e não correlacionadas, por outras palavras, existe uma correlação significativa entre as variáveis em questão. Isso significa que as variáveis não podem ser consideradas independentes e que existe algum grau de relação entre elas.

# Estandardizar os dados

```{r}
data_scaled <- scale(Irlanda)
data_scaled %>% glimpse()
```

# PCA

Nesta parte, passaremos então para o processo de criação de PCA's. Podemos então começar por pensar algumas ideias por alto, podendo ser estas:

* **PCA de Desempenho Acadêmico**:
    - Variáveis de interesse: Pontuações em diferentes domínios acadêmicos, como leitura, matemática e ciências.
    - Objetivo: Compreender a estrutura subjacente do desempenho acadêmico dos alunos e identificar padrões gerais de habilidades e competências.

* **PCA de Fatores Socioeconômicos**:
    - Variáveis de interesse: Variáveis socioeconômicas, como o nível de educação dos pais, ocupação dos pais, renda familiar, acesso a recursos educacionais, etc.
    - Objetivo: Explorar as relações entre os fatores socioeconômicos e o desempenho acadêmico dos alunos, bem como identificar grupos de alunos com perfis socioeconômicos semelhantes.

* **PCA de Atitudes e Comportamentos**:
    - Variáveis de interesse: Variáveis relacionadas a atitudes, motivação, autoeficácia, disciplina, participação em atividades extracurriculares, etc.
    - Objetivo: Identificar padrões de atitudes e comportamentos dos alunos que podem influenciar seu desempenho académico e bem-estar geral.

* **PCA de Ambiente Escolar**:
    - Variáveis de interesse: Variáveis relacionadas ao ambiente escolar, como tamanho da turma, recursos educacionais disponíveis, clima escolar, relacionamento professor-aluno, etc.
    - Objetivo: Explorar a relação entre o ambiente escolar e o desempenho dos alunos, bem como identificar características importantes do ambiente que afetam o aprendizado.

## Colunas

```{r}
colunas <- colnames(data_scaled)
colunas
```
## Visualizar correlações interessantes
```{r}
correlation1 <- cor(data_scaled[, -1], data_scaled[, 1])
# corrplot(correlation1)
# Definir o limite de correlação desejado
limite_correlacao <- 0.3

# Identificar as colunas com correlação forte
colunas_fortes <- row.names(correlation1)[which(abs(correlation1) > limite_correlacao)]

colunas_fortes <- append(colunas_fortes, "PV1SCIE")
  
# Exibir as colunas com correlação forte
print(colunas_fortes)
```


## Criação do PCA

```{r}
pc1 <- principal(data_scaled, nfactors=ncol(data_scaled), rotate="none")
round(pc1$values,3)
```
```{r}
plot(pc1$values, type = "b", main = "Scree plot for Irland dataset", 
     xlab = "Number of PC", ylab = "Eigenvalue")
# Entre 17 e 22
# Colunas a ver:
## Parents - MOTHER + FATHER
## Number of classes (usar o total apenas)
## Learning Time
```
## Experiência com 17

```{r}
pc17 <- principal(data_scaled, nfactors = 17, rotate = "none")
pc17$loadings
pc17r <- principal(data_scaled, nfactors= 17, rotate="varimax")
pc17r$loadings
round(pc17$communality,2)
```

```{r}
pc17sc <- principal(data_scaled, nfactors=17, rotate="none", scores = TRUE)

round(pc17sc$scores,3)
mean(pc17sc$scores[,1])
sd(pc17sc$scores[,1])
```
## Experiência com 12
```{r}
pc12 <- principal(data_scaled, nfactors = 12, rotate = "none")
pc12$loadings
pc12r <- principal(data_scaled, nfactors= 12, rotate="varimax")
pc12r$loadings
round(pc12$communality,2)
```

```{r}
pc12sc <- principal(data_scaled, nfactors=12, rotate="none", scores = TRUE)

round(pc12sc$scores,3)
mean(pc12sc$scores[,1])
sd(pc12sc$scores[,1])
```

